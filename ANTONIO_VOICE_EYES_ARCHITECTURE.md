# ðŸ‘€ðŸŽ™ï¸ Antonio Voice + Eyes - Complete Architecture

**Hardware**: Waveshare ESP32-S3 DualEye LCD 1.28" + Raspberry Pi 5

---

## ðŸŽ¯ Sistema Completo

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                    ANTONIO FULL SYSTEM                       â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”          WiFi/MQTT          â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   RASPBERRY PI 5     â”‚â—„â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚   ESP32-S3 DUALEYE   â”‚
â”‚                      â”‚                             â”‚                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚  Antonio Brain   â”‚ â”‚                             â”‚ â”‚   Left Eye       â”‚ â”‚
â”‚ â”‚  (Gemma 3 1B)   â”‚ â”‚                             â”‚ â”‚  (240x240 IPS)   â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                             â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                      â”‚                             â”‚                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Speech-to-Text   â”‚ â”‚        Commands:            â”‚ â”‚  Right Eye       â”‚ â”‚
â”‚ â”‚   (Whisper)      â”‚ â”‚     â€¢ Eye expression       â”‚ â”‚  (240x240 IPS)   â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚     â€¢ Voice output         â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                      â”‚     â€¢ Emotion sync         â”‚                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Text-to-Speech   â”‚ â”‚â—„â”€â”€â”€â”€â”€â”€ Audio Stream â”€â”€â”€â”€â”€â”€â”€â”¤ â”‚  ES8311 Codec    â”‚ â”‚
â”‚ â”‚ (Piper/Coqui)   â”‚ â”‚                             â”‚ â”‚  + Speaker       â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                             â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                      â”‚                             â”‚                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚â”€â”€â”€â”€â”€â”€â–º Audio Stream â”€â”€â”€â”€â”€â”€â”€â–ºâ”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚ Emotion Detector â”‚ â”‚                             â”‚ â”‚  ES7210 ADC      â”‚ â”‚
â”‚ â”‚  (from text)     â”‚ â”‚                             â”‚ â”‚  + Microphone    â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                             â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                      â”‚                             â”‚                      â”‚
â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚                             â”‚ â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚ â”‚   EvoMemory      â”‚ â”‚                             â”‚ â”‚  Touch Input     â”‚ â”‚
â”‚ â”‚    Tools         â”‚ â”‚                             â”‚ â”‚  (CST816S)       â”‚ â”‚
â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚                             â”‚ â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ðŸ§  Flow Completo

### 1ï¸âƒ£ Voice Input Flow:

```
Microfono (ESP32) â†’ ES7210 ADC â†’ WiFi Stream â†’ Raspberry Pi â†’ Whisper STT â†’ Testo
```

### 2ï¸âƒ£ Antonio Processing:

```
Testo â†’ Antonio Brain (Gemma 3) â†’ Risposta + Emotion Detection â†’ Comando Eyes + TTS
```

### 3ï¸âƒ£ Voice Output Flow:

```
Raspberry Pi â†’ Piper TTS (con tonalitÃ ) â†’ Audio Stream â†’ ESP32 â†’ ES8311 Codec â†’ Speaker
```

### 4ï¸âƒ£ Eyes Expression Flow:

```
Emotion Detected â†’ Comando MQTT â†’ ESP32 â†’ Eye Animation Renderer â†’ Dual Display
```

---

## ðŸŽ­ Eye Expressions (Emozioni)

### Emozioni Disponibili:

| Emozione | Descrizione | Animazione | Use Case |
|----------|-------------|------------|----------|
| **NEUTRAL** | Normale, rilassato | Pupille centrate, blink occasionale | Idle state |
| **HAPPY** | Felice, sorridente | Pupille grandi, "sorriso" con forma | Risposta positiva |
| **THINKING** | Pensieroso | Pupille guardano su/lato, movimento lento | Sta elaborando |
| **SURPRISED** | Sorpreso | Pupille molto grandi, occhi aperti | Informazione nuova |
| **FOCUSED** | Concentrato | Pupille piccole, fissi su punto | Usa tool, calcola |
| **CONFUSED** | Confuso | Pupille piccole, movimento erratico | Non ha capito |
| **TIRED** | Stanco | Palpebre semi-chiuse, blink lento | Carico alto |
| **LISTENING** | In ascolto | Pupille che seguono "suono" | Durante voice input |
| **SPEAKING** | Sta parlando | Blink sincronizzato con voce | Durante TTS output |
| **ERROR** | Errore | Occhi rossi, lampeggiano | Errore di sistema |

### Componenti Grafici:

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Singolo Occhio:       â”‚
â”‚                         â”‚
â”‚   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”     â”‚
â”‚   â”‚   â•­â”€â”€â”€â”€â”€â•®     â”‚     â”‚ â† Palpebra superiore (animabile)
â”‚   â”‚   â”‚ â—   â”‚     â”‚     â”‚ â† Pupilla (dimensione + posizione variabile)
â”‚   â”‚   â•°â”€â”€â”€â”€â”€â•¯     â”‚     â”‚ â† Palpebra inferiore (animabile)
â”‚   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     â”‚
â”‚                         â”‚
â”‚   + Sfondo iris coloratoâ”‚
â”‚   + Riflessi dinamici   â”‚
â”‚   + Vene/texture        â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Animazioni:

- **Blink**: Chiusura/apertura palpebre (100-200ms)
- **Look Around**: Movimento pupille in direzioni
- **Dilate**: Cambio dimensione pupille
- **Wink**: Chiusura un occhio solo
- **Squint**: Socchiudere occhi
- **Wide Open**: Apertura massima

---

## ðŸŽ¤ Voice System

### Speech-to-Text (STT):

**Opzione 1: Whisper.cpp (Locale - Raccomandato)**
```bash
Modello: tiny.en o base.en
Dimensione: ~75MB (tiny) o ~140MB (base)
Latenza: ~1-2 secondi
Accuratezza: 85-90%
Privacy: âœ… Tutto locale
```

**Opzione 2: Vosk (Lightweight)**
```bash
Modello: vosk-model-small-it-0.22
Dimensione: ~45MB
Latenza: ~0.5-1 secondo
Accuratezza: 75-85%
Privacy: âœ… Tutto locale
```

**Opzione 3: Google Cloud STT (Cloud)**
```bash
Latenza: ~0.5 secondi
Accuratezza: 95%+
Privacy: âŒ Invia audio al cloud
```

### Text-to-Speech (TTS):

**Opzione 1: Piper TTS (Locale - Raccomandato)**
```bash
Modello: it_IT-riccardo-x_low
Dimensione: ~15MB
QualitÃ : Buona, naturale
EmotivitÃ : â­â­â­ (SSML per pitch/speed)
Latenza: ~0.5 secondi
```

**Opzione 2: Coqui TTS**
```bash
Modello: tts_models/it/mai_female/glow-tts
QualitÃ : Ottima
EmotivitÃ : â­â­â­â­ (piÃ¹ controllo)
Latenza: ~1-2 secondi
```

**Opzione 3: ElevenLabs API (Cloud - Massima QualitÃ )**
```bash
QualitÃ : Eccellente, ultra-naturale
EmotivitÃ : â­â­â­â­â­ (controllo completo)
Latenza: ~1 secondo
Costo: ~$0.30 per 1000 caratteri
```

### TonalitÃ  Vocali:

Con SSML (Speech Synthesis Markup Language):

```python
# Esempio Piper TTS con emozioni
{
    "HAPPY": {"rate": 1.1, "pitch": 1.2},      # PiÃ¹ veloce, piÃ¹ acuto
    "SAD": {"rate": 0.9, "pitch": 0.8},        # PiÃ¹ lento, piÃ¹ grave
    "EXCITED": {"rate": 1.3, "pitch": 1.3},    # Molto veloce, acuto
    "TIRED": {"rate": 0.8, "pitch": 0.9},      # Lento, leggermente grave
    "CONFUSED": {"rate": 0.95, "pitch": 1.1},  # Leggermente esitante
    "FOCUSED": {"rate": 1.0, "pitch": 1.0},    # Normale, chiaro
}
```

---

## ðŸ”Œ Comunicazione Pi â†” ESP32

### Protocollo: MQTT (Raccomandato)

**PerchÃ© MQTT:**
- âœ… WiFi nativo su ESP32
- âœ… Low latency (~10-50ms)
- âœ… Bidirectional
- âœ… Topic-based (organizzazione chiara)
- âœ… QoS support

**MQTT Topics:**

```
antonio/eyes/expression     â†’ Comando emozione occhi
antonio/eyes/position       â†’ Posizione pupille
antonio/eyes/animation      â†’ Animazione speciale
antonio/audio/stream/in     â†’ Audio mic â†’ Pi
antonio/audio/stream/out    â†’ Audio Pi â†’ speaker
antonio/status              â†’ Status ESP32
antonio/config              â†’ Configurazione
```

**Messaggio Esempio:**

```json
{
  "topic": "antonio/eyes/expression",
  "payload": {
    "emotion": "HAPPY",
    "duration": 2000,
    "intensity": 0.8,
    "transition": "smooth"
  }
}
```

### Alternativa: HTTP REST API

```
POST http://esp32.local/api/eyes
{
  "emotion": "THINKING",
  "duration": 1500
}
```

---

## ðŸŽ¨ Emotion Detection

### Come Detectare Emozione dal Testo:

**Metodo 1: Rule-Based (Semplice, Veloce)**

```python
EMOTION_KEYWORDS = {
    "HAPPY": ["felice", "ottimo", "bene", "perfetto", "eccellente", "ðŸ˜Š"],
    "CONFUSED": ["non capisco", "cosa intendi", "puoi spiegare", "?"],
    "THINKING": ["fammi pensare", "vediamo", "analizziamo", "consideriamo"],
    "SURPRISED": ["wow", "incredibile", "davvero", "!"],
    "ERROR": ["errore", "non funziona", "problema", "fallito"],
}

def detect_emotion(text):
    text_lower = text.lower()
    for emotion, keywords in EMOTION_KEYWORDS.items():
        if any(kw in text_lower for kw in keywords):
            return emotion
    return "NEUTRAL"
```

**Metodo 2: Sentiment Analysis (PiÃ¹ Accurato)**

```python
from transformers import pipeline

sentiment = pipeline("sentiment-analysis",
                     model="nlptown/bert-base-multilingual-uncased-sentiment")

def detect_emotion_advanced(text):
    result = sentiment(text)[0]
    score = int(result['label'][0])  # 1-5 stars

    if score >= 4:
        return "HAPPY"
    elif score <= 2:
        return "SAD"
    else:
        return "NEUTRAL"
```

**Metodo 3: Dal Contesto di Antonio**

```python
# Antonio puÃ² includere emozione nella sua risposta
response_format = {
    "text": "Certo! 2+2 fa 4.",
    "emotion": "HAPPY",  # â† Antonio decide l'emozione
    "tools_used": []
}
```

---

## ðŸ“Š Performance Targets

| Componente | Target Latency | Actual |
|------------|----------------|--------|
| **Voice Input (STT)** | < 2s | TBD |
| **Antonio Processing** | < 3s | ~2s âœ… |
| **Voice Output (TTS)** | < 1s | TBD |
| **Eye Animation** | < 100ms | TBD |
| **MQTT Communication** | < 50ms | TBD |
| **Total Userâ†’Response** | < 6s | TBD |

---

## ðŸ› ï¸ Tech Stack

### Raspberry Pi Software:

```yaml
Language: Python 3.11
Dependencies:
  - whisper.cpp (STT)
  - piper-tts (TTS)
  - paho-mqtt (Communication)
  - pyaudio (Audio I/O)
  - numpy (Audio processing)
  - ollama (Antonio brain)
```

### ESP32-S3 Firmware:

```yaml
Framework: Arduino / ESP-IDF
Language: C++
Libraries:
  - TFT_eSPI (Display driver)
  - PubSubClient (MQTT)
  - ArduinoJson (JSON parsing)
  - ESP32-audioI2S (Audio I/O)
  - lvgl (Graphics - optional)
```

---

## ðŸ”§ Hardware Setup

### Connessioni:

```
ESP32-S3 DualEye:
â”œâ”€â”€ Power: USB-C (5V) o batteria Li-Po 3.7V
â”œâ”€â”€ WiFi: Connesso alla stessa rete del Raspberry Pi
â”œâ”€â”€ Speaker: MX1.25 2PIN (8Î© 2W)
â”œâ”€â”€ Microphone: Onboard (ES7210)
â””â”€â”€ (Optional) Touch: I2C CST816S

Raspberry Pi 5:
â”œâ”€â”€ Power: USB-C PD (27W)
â”œâ”€â”€ Network: WiFi/Ethernet (stesso network ESP32)
â”œâ”€â”€ (Optional) USB Mic: Se non usi ESP32 mic
â””â”€â”€ (Optional) USB Speaker: Se non usi ESP32 speaker
```

### Audio Routing Options:

**Opzione A: Audio tutto su ESP32 (Raccomandato)**
```
User â†’ ESP32 Mic â†’ WiFi Stream â†’ Pi (Whisper) â†’ Text
Text â†’ Pi (Piper) â†’ WiFi Stream â†’ ESP32 Speaker â†’ User
```
âœ… Tutto wireless
âœ… ESP32 puÃ² essere portable
âŒ Latenza WiFi (~50-100ms extra)

**Opzione B: Audio diretto su Pi**
```
User â†’ Pi USB Mic â†’ Pi (Whisper) â†’ Text
Text â†’ Pi (Piper) â†’ Pi USB Speaker â†’ User
ESP32 solo per Eyes
```
âœ… Latenza minore
âŒ Pi meno portable
âŒ Cavi extra

---

## ðŸ“ Project Structure

```
/home/pi/antonio/
â”œâ”€â”€ brain/
â”‚   â”œâ”€â”€ server.py                    # Antonio main server (UPDATED)
â”‚   â”œâ”€â”€ emotion_detector.py          # NEW: Emotion detection
â”‚   â””â”€â”€ voice_handler.py              # NEW: Voice I/O manager
â”‚
â”œâ”€â”€ voice/
â”‚   â”œâ”€â”€ stt/
â”‚   â”‚   â”œâ”€â”€ whisper_stt.py           # NEW: Whisper speech-to-text
â”‚   â”‚   â””â”€â”€ models/                   # Whisper models
â”‚   â”‚       â””â”€â”€ ggml-tiny.en.bin
â”‚   â”‚
â”‚   â””â”€â”€ tts/
â”‚       â”œâ”€â”€ piper_tts.py             # NEW: Piper text-to-speech
â”‚       â””â”€â”€ models/
â”‚           â””â”€â”€ it_IT-riccardo-x_low.onnx
â”‚
â”œâ”€â”€ eyes/
â”‚   â”œâ”€â”€ mqtt_bridge.py               # NEW: MQTT communication with ESP32
â”‚   â”œâ”€â”€ emotion_mapper.py            # NEW: Emotion â†’ Eye expression mapping
â”‚   â””â”€â”€ config.json                  # Eye animation configs
â”‚
â”œâ”€â”€ esp32/
â”‚   â””â”€â”€ antonio_eyes/                # NEW: ESP32 firmware
â”‚       â”œâ”€â”€ antonio_eyes.ino         # Main firmware
â”‚       â”œâ”€â”€ eye_renderer.cpp         # Eye graphics engine
â”‚       â”œâ”€â”€ mqtt_handler.cpp         # MQTT client
â”‚       â”œâ”€â”€ audio_stream.cpp         # Audio I/O
â”‚       â””â”€â”€ animations.h             # Eye animation definitions
â”‚
â”œâ”€â”€ config/
â”‚   â”œâ”€â”€ voice_config.yaml
â”‚   â”œâ”€â”€ eyes_config.yaml
â”‚   â””â”€â”€ mqtt_config.yaml
â”‚
â””â”€â”€ scripts/
    â”œâ”€â”€ setup_voice.sh               # NEW: Install voice deps
    â”œâ”€â”€ setup_esp32.sh               # NEW: Flash ESP32 firmware
    â””â”€â”€ test_voice_eyes.sh           # NEW: Test complete system
```

---

## ðŸš€ Implementation Plan

### Phase 1: Voice Input (STT) âœ… First

**Tasks:**
1. Install Whisper.cpp on Pi
2. Create voice input service
3. Test mic â†’ text pipeline
4. Integrate with Antonio server

**Test:**
```bash
python3 voice/stt/whisper_stt.py
# Parla: "Ciao Antonio"
# Output: "ciao antonio"
```

### Phase 2: Voice Output (TTS) âœ… Second

**Tasks:**
1. Install Piper TTS on Pi
2. Create voice output service with emotion control
3. Test text â†’ audio â†’ speaker
4. Add SSML for tonalitÃ 

**Test:**
```bash
python3 voice/tts/piper_tts.py "Ciao! Come stai?" --emotion HAPPY
# Speaker output: voce allegra
```

### Phase 3: Eye Animations âœ… Third

**Tasks:**
1. Setup ESP32 development environment
2. Create eye rendering engine
3. Implement 10 emotion animations
4. Test on dual displays

**Test:**
```bash
# Upload firmware to ESP32
arduino-cli upload -p /dev/ttyUSB0
# Eyes show HAPPY expression
```

### Phase 4: Communication âœ… Fourth

**Tasks:**
1. Setup MQTT broker on Pi (Mosquitto)
2. Implement MQTT bridge on Pi
3. Implement MQTT client on ESP32
4. Test bidirectional communication

**Test:**
```bash
mosquitto_pub -t antonio/eyes/expression -m '{"emotion":"THINKING"}'
# Eyes change to THINKING
```

### Phase 5: Emotion Detection âœ… Fifth

**Tasks:**
1. Create emotion detector from text
2. Integrate with Antonio responses
3. Map emotions to eye expressions + voice tone
4. Test emotion flow

**Test:**
```bash
# Antonio risponde: "Perfetto! 2+2 fa 4."
# Emotion detected: HAPPY
# Eyes: HAPPY
# Voice: Pitch 1.2, Rate 1.1
```

### Phase 6: Full Integration âœ… Final

**Tasks:**
1. Update Antonio server with voice + eyes
2. Create startup scripts
3. Full system testing
4. Performance optimization

**Test:**
```bash
# Completo voice conversation test
User (voice): "Quanto fa 1847 per 2935?"
Antonio (eyes): LISTENING â†’ THINKING â†’ FOCUSED
Antonio (voice): "UserÃ² il calcolatore... il risultato Ã¨ 5,421,245"
Antonio (eyes): HAPPY
```

---

## ðŸŽ¯ Success Metrics

| Metric | Target | Priority |
|--------|--------|----------|
| **STT Accuracy** | > 85% | HIGH |
| **TTS Quality** | Natural voice | HIGH |
| **Eye Animation Smoothness** | 30+ FPS | MEDIUM |
| **Total Response Latency** | < 6s | HIGH |
| **Emotion Detection Accuracy** | > 75% | MEDIUM |
| **System Uptime** | > 99% | HIGH |
| **WiFi Latency** | < 100ms | MEDIUM |

---

## ðŸ’¡ Future Enhancements

### V2 Features:

1. **Wake Word Detection**: "Hey Antonio" per attivare
2. **Multiple Voices**: Cambia voce in base a contesto
3. **Face Tracking**: Pupille seguono persona (con camera)
4. **Gesture Recognition**: Touch su occhi per comandi
5. **Music Sync**: Occhi ballano a ritmo musica
6. **Multi-Language**: IT/EN/ES voice support
7. **Offline Mode**: Tutto locale, no WiFi needed
8. **3D Eyes**: Effetti parallax per profonditÃ 

### V3 Advanced:

1. **GPT Vision**: ESP32 con camera, Antonio "vede"
2. **LipSync**: Sincronizzazione labiale (se aggiungi bocca display)
3. **Personality Modes**: Diverse personalitÃ  (serio, giocoso, ecc)
4. **Dream Mode**: Animazioni ambient quando idle
5. **Multi-Antonio**: PiÃ¹ ESP32, network di Antonio

---

## ðŸ“– Quick Start (After Implementation)

```bash
# 1. Start MQTT broker
sudo systemctl start mosquitto

# 2. Start Antonio voice server
cd /home/pi/antonio
python3 brain/server.py --voice-enabled --eyes-enabled

# 3. Flash ESP32 (first time only)
cd esp32/antonio_eyes
arduino-cli upload -p /dev/ttyUSB0

# 4. Talk to Antonio!
# Speak: "Ciao Antonio, quanto fa 2+2?"
# Antonio eyes: LISTENING â†’ THINKING â†’ HAPPY
# Antonio voice: "Fa 4!"
```

---

## ðŸ†˜ Troubleshooting

### Voice not working:
```bash
# Check mic
arecord -l
# Check speaker
aplay -l
# Test MQTT
mosquitto_sub -t antonio/#
```

### Eyes not responding:
```bash
# Check ESP32 WiFi
ping esp32.local
# Check MQTT connection
mosquitto_pub -t antonio/eyes/expression -m '{"emotion":"HAPPY"}'
```

### High latency:
```bash
# Check network
ping -c 10 esp32.local
# Check Pi CPU
htop
# Reduce Whisper model size (use tiny instead of base)
```

---

**Version**: v0.7.0 (Voice + Eyes Edition)
**Status**: ðŸ“‹ PLANNING COMPLETE - READY FOR IMPLEMENTATION
**Hardware Required**: ESP32-S3 DualEye + Raspberry Pi 5
**Estimated Dev Time**: 2-3 weeks

_"Antonio sta per avere voce ed emozioni!"_ ðŸŽ™ï¸ðŸ‘€âœ¨
