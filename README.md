# ğŸ§  Antonio Gemma3 Evo Q4

**The first self-learning, local, and auto-evolutionary small language model**
*Il primo modello linguistico leggero, locale e auto-evolutivo*

[![License: Gemma](https://img.shields.io/badge/License-Gemma-blue.svg)](https://ai.google.dev/gemma/terms)
[![Python 3.8+](https://img.shields.io/badge/python-3.8+-blue.svg)](https://www.python.org/downloads/)
[![Raspberry Pi](https://img.shields.io/badge/Raspberry%20Pi-4%2F5-red.svg)](https://www.raspberrypi.org/)
[![Ollama](https://img.shields.io/badge/Ollama-Ready-green.svg)](https://ollama.com)

---

## ğŸŒŸ What Makes It Special

Antonio Gemma3 Evo Q4 is not just another quantized LLM. It's a **micro-intelligence** that:

- ğŸ§¬ **Learns from every conversation** â€” Saves "neurons" with input, output, confidence, and mood
- ğŸ” **RAG-Lite Memory** â€” Retrieves past experiences using BM25 (no heavy dependencies)
- ğŸ¯ **Self-evaluates** â€” Assigns confidence scores (0-1) to every response
- ğŸŒ± **Auto-evolves** â€” Generates new reasoning rules from accumulated neurons
- ğŸ”’ **100% Offline** â€” Runs completely local on Raspberry Pi 4 (4GB RAM)
- ğŸŒ **Bilingual** â€” Auto-detects IT/EN and responds in the same language
- âš¡ **Fast** â€” 3.32 tokens/s sustained on Pi 4 with Q4_K_M quantization

> "The little brain that grows with you" ğŸ§ 

ğŸ“Š **[View Complete Benchmark Report](BENCHMARK_REPORT.md)** â€” Performance, reliability, and stability metrics

---

## ğŸ—ï¸ Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Antonio Gemma3 Evo Q4 - Evolution Layer    â”‚
â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤
â”‚                                             â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ EvoMemoryâ„¢   â”‚â—„â”€â”€â”€â”€â–ºâ”‚  RAG-Lite       â”‚ â”‚
â”‚  â”‚ (SQLite)     â”‚      â”‚  BM25 Search    â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â–²                      â–²            â”‚
â”‚         â”‚                      â”‚            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚    Inference Engine (llama.cpp)        â”‚ â”‚
â”‚  â”‚    â€¢ Q4_0 / Q4_K_M                     â”‚ â”‚
â”‚  â”‚    â€¢ Optimized for Pi 4                â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚         â–²                      â”‚            â”‚
â”‚         â”‚                      â–¼            â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚ Action Broker  â”‚    â”‚  Confidence      â”‚ â”‚
â”‚  â”‚ (MCP-ready)    â”‚    â”‚  Auto-Eval       â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â”‚                                             â”‚
â”‚  FastAPI Server (REST + WebSocket)         â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸš€ Quick Start

### Prerequisites

- Python 3.8+
- llama.cpp (already included in parent directory)
- Raspberry Pi 4/5 with 4GB RAM (or Mac/Linux for development)

### 1. Installation

```bash
cd antonio-evo
bash scripts/install.sh
```

This will:
- Create virtual environment
- Install dependencies
- Initialize SQLite database
- Link model files from `../artifacts/`

### 2. Download/Quantize Model

If you don't have the model yet:

```bash
cd ..
bash scripts/quantize_gemma.sh
```

This creates:
- `artifacts/gemma3-1b-q4_0.gguf` (720 MB, faster)
- `artifacts/gemma3-1b-q4_k_m.gguf` (806 MB, better quality)

### 3. Start the Server

```bash
source .venv/bin/activate
python3 api/server.py
```

Visit: **http://localhost:8000/docs** for interactive API documentation

### 4. Chat!

```bash
curl -X POST http://localhost:8000/chat \
  -H "Content-Type: application/json" \
  -d '{"message": "Ciao! Come funziona la tua memoria evolutiva?"}'
```

Response:
```json
{
  "response": "La mia memoria evolutiva funziona attraverso neuroni che salvano input, output, e confidenza...",
  "confidence": 0.82,
  "confidence_label": "alta",
  "reasoning": "risposta dettagliata; trovate 1 espressioni di certezza",
  "neuron_id": 42,
  "tokens_per_second": 3.67,
  "rag_used": true
}
```

---

## ğŸ’¡ Core Features

### 1ï¸âƒ£ EvoMemoryâ„¢ â€” Living Memory

Every conversation creates a **neuron**:

```python
{
  "id": 123,
  "input_text": "Accendi il LED rosso",
  "output_text": "OK, attivo GPIO 17 su HIGH",
  "confidence": 0.85,
  "mood": "positive",
  "user_feedback": +1,  # ğŸ‘ from user
  "skill_id": "gpio_control",
  "timestamp": "2025-10-21T14:30:00Z"
}
```

**Features:**
- Auto-pruning of low-confidence old neurons
- Neuron compression (similar patterns â†’ meta-neurons)
- Context-aware retrieval via hash matching

### 2ï¸âƒ£ RAG-Lite â€” Smart Retrieval

Uses **BM25** (pure Python) to retrieve relevant past experiences:

```python
# Query: "Come controllo un LED?"
# Retrieves:
# - "Accendi il LED rosso" â†’ score: 0.87
# - "Spegni il LED" â†’ score: 0.72
```

No FAISS, no ChromaDB, no heavy dependencies!

### 3ï¸âƒ£ Confidence Scoring â€” Self-Awareness

Every response gets a confidence score (0-1):

- **Pattern analysis**: "non sono sicuro", "forse" â†’ lower confidence
- **Length check**: too short â†’ suspicious
- **Repetition detection**: hallucination indicator
- **Context matching**: prompt vs output coherence

### 4ï¸âƒ£ Auto-Evolution (Coming Soon)

Every 100 interactions:
1. Analyze neurons
2. Group similar patterns
3. Generate new reasoning rules
4. Update `instinct.json`

Example rule:
```json
{
  "rule": "never_claim_internet_when_offline",
  "trigger_pattern": "detect_hallucination",
  "priority": 1
}
```

### 5ï¸âƒ£ Energy-Aware Inference

Monitors CPU temperature and adjusts:

```python
if cpu_temp > 75Â°C:
    reduce_context_to(512)
    switch_to_Q4_0()  # faster quantization
```

Prevents thermal throttling on Raspberry Pi!

---

## ğŸ“Š API Endpoints

### `POST /chat`

Main chat endpoint with RAG support.

**Request:**
```json
{
  "message": "What is EvoMemory?",
  "use_rag": true,
  "skill_id": "conversation"
}
```

**Response:**
```json
{
  "response": "EvoMemory is a SQLite-based system that stores...",
  "confidence": 0.78,
  "confidence_label": "high",
  "neuron_id": 456,
  "tokens_per_second": 3.67,
  "rag_used": true
}
```

### `POST /feedback`

Submit user feedback on a neuron.

```json
{
  "neuron_id": 456,
  "feedback": 1  // -1 (bad), 0 (neutral), +1 (good)
}
```

### `GET /stats`

System statistics.

```json
{
  "neurons_total": 1234,
  "meta_neurons": 42,
  "rules_active": 8,
  "avg_confidence": 0.73,
  "uptime": "02:15:30"
}
```

### `GET /neurons/recent?limit=10`

Get recent neurons.

### `WebSocket /ws`

Real-time chat with streaming support.

---

## ğŸ› ï¸ Development

### Project Structure

```
antonio-evo/
â”œâ”€â”€ core/
â”‚   â”œâ”€â”€ evomemory/
â”‚   â”‚   â”œâ”€â”€ schema.py          # SQLite database schema
â”‚   â”‚   â”œâ”€â”€ neuron_store.py    # CRUD operations
â”‚   â”‚   â””â”€â”€ rag_lite.py        # BM25 retrieval
â”‚   â”œâ”€â”€ inference/
â”‚   â”‚   â”œâ”€â”€ llama_wrapper.py   # llama.cpp integration
â”‚   â”‚   â””â”€â”€ confidence.py      # Self-evaluation
â”‚   â”œâ”€â”€ tools/                 # (Coming soon)
â”‚   â”‚   â”œâ”€â”€ broker.py          # Action Broker
â”‚   â”‚   â””â”€â”€ gpio/              # Raspberry Pi GPIO
â”‚   â””â”€â”€ growth/                # (Coming soon)
â”‚       â””â”€â”€ rule_generator.py  # Auto-evolution
â”œâ”€â”€ api/
â”‚   â””â”€â”€ server.py              # FastAPI server
â”œâ”€â”€ data/
â”‚   â”œâ”€â”€ evomemory/
â”‚   â”‚   â”œâ”€â”€ neurons.db         # SQLite database
â”‚   â”‚   â””â”€â”€ skills/            # Skill modules
â”‚   â””â”€â”€ models/                # Model symlinks
â”œâ”€â”€ scripts/
â”‚   â””â”€â”€ install.sh             # Installation script
â”œâ”€â”€ tests/                     # Unit tests
â””â”€â”€ requirements.txt
```

### Running Tests

```bash
pytest tests/
```

### Adding a New Skill

1. Create skill definition in `data/evomemory/skills/my_skill.json`:

```json
{
  "id": "my_skill",
  "name": "My Awesome Skill",
  "description": "What it does",
  "enabled": true
}
```

2. Tag neurons with `skill_id="my_skill"` when saving

3. Query skill-specific neurons:

```python
neurons = store.get_recent_neurons(skill_id="my_skill")
```

---

## ğŸ¯ Use Cases

- **ğŸ  Offline Home Automation** â€” Control GPIO, sensors, actuators
- **ğŸ™ï¸ Voice Assistants** â€” Fast enough for real-time speech (3.67 t/s)
- **ğŸ” Privacy-First AI** â€” Medical, legal, personal data (100% local)
- **ğŸŒ Bilingual Chatbots** â€” Customer support, documentation (IT/EN)
- **ğŸ“š Educational Projects** â€” Learn AI/ML on affordable hardware
- **ğŸ­ Embedded Systems** â€” Industrial applications requiring offline inference

---

## ğŸ“ˆ Roadmap

- [x] **v0.1** â€” Core EvoMemory + RAG + Confidence
- [x] **v0.2** â€” FastAPI server + WebSocket
- [ ] **v0.3** â€” Rule Regeneration system
- [ ] **v0.4** â€” Action Broker + Tool Registry (MCP-ready)
- [ ] **v0.5** â€” GPIO control for Raspberry Pi
- [ ] **v0.6** â€” Voice integration (Whisper.cpp + TTS)
- [ ] **v0.7** â€” Social Learning (opt-in neuron sharing)
- [ ] **v0.8** â€” Multi-model support (Qwen, Phi, Mistral)

---

## ğŸ¤ Contributing

Contributions are welcome! This is an **open-source passion project**.

Ideas? Bugs? Feature requests?
Open an issue or PR on GitHub!

---

## ğŸ“œ License

This model is a **derivative work** of [Google's Gemma 3 1B](https://huggingface.co/google/gemma-3-1b-it).

**License**: Gemma License
Please review and comply with the [Gemma License Terms](https://ai.google.dev/gemma/terms).

**Quantization, optimization, and EvoLayer** by [Antonio](https://github.com/antconsales).

---

## ğŸ”— Links

- **Ollama**: https://ollama.com/antconsales/antonio-gemma3-evo-q4
- **Hugging Face**: https://huggingface.co/chill123/antonio-gemma3-evo-q4
- **GitHub**: https://github.com/antconsales/antonio-gemma3-evo-q4

---

## ğŸŒŸ Star History

If you like this project, give it a â­ on GitHub!

---

**Built with â¤ï¸ for offline AI and edge computing**
*Empowering local intelligence, one Raspberry Pi at a time.* ğŸ§ ğŸ‡®ğŸ‡¹

---

## ğŸ’¬ FAQ

**Q: Can it really learn from conversations?**
A: Yes! Every chat saves a neuron with input, output, confidence, and user feedback. RAG retrieves relevant neurons for future queries.

**Q: How is it different from regular Gemma 3?**
A: It adds EvoMemoryâ„¢, RAG, confidence scoring, and auto-evolution. It's not just inferenceâ€”it's a learning system.

**Q: Will it work on Raspberry Pi 3?**
A: Probably, but slower. Optimized for Pi 4 (4GB) and Pi 5.

**Q: Can I use it offline?**
A: 100%! No internet required. All inference and learning happens locally.

**Q: Is my data safe?**
A: Absolutely. Everything stays in your SQLite database. No telemetry, no tracking, no cloud.

**Q: Can I add custom tools (GPIO, sensors, etc.)?**
A: Coming in v0.4! Action Broker with MCP compatibility.

**Q: Does it support other languages?**
A: Currently IT/EN. More languages can be added via system prompt customization.

---

**Questions? Ideas? Let's chat!** ğŸ’¬
